
library ("ROCR")
library ("PresenceAbsence")
library("randomForest")
library("rms")
library("XLConnect")
library ("plyr")
library("RODBC")
library(plyr)
require(gbm)
require(caret)

####################################### Load data, understanding, DQ

setwd("/Users/dilip.patel/Google Drive/Learning/Analytics/Kaggle/Santander_Classification")

getwd()

# Importing data into R

train <- read.csv("train.csv")
predict <- read.csv("test.csv")
sample_submission <- read.csv("sample_submission.csv")

# price quotes from our suppliers
str(train)
summary(train)

str(predict)
#summary(test)
colnames(train)
colnames(predict)

#---------------------------------> Preparing Training Data

train <- train[,-1]
train <- train[ , order(names(train))]
predict <- predict[ , order(names(predict))]

train <- cbind(train[,365],train[,-365])
colnames(train)[1] <- "TARGET"
train[,1] <- factor(train[,1])

predict <- cbind(predict[,27],predict[,-27])
colnames(predict)[1] <- "ID"
predict[,1] <- factor(predict[,1])


# Remove variables with no more than one value - predict
for (i in 1:dim(predict)[2]){
  if(length(unique(predict[,i])) < 2){
    print(colnames(predict)[i])
    predict <- predict[,-i]
  }
}

colnameskeep_initial <- colnames(train[,(colnames(train) %in% colnames(predict))])
colnameskeep_initial <- c("TARGET",colnameskeep_initial)
train = train[,colnameskeep_initial]
colnames(train)

# Remove variables with no more than one value - train
for (i in 1:dim(train)[2]){
  if(length(unique(train[,i])) < 2){
    print(colnames(train)[i])
    #train <- train[,-i]
  }
}

# Remove bad features 
colums_drops_initial <- c("imp_trasp_var33_out_ult1","imp_amort_var18_ult1","saldo_var18","imp_reemb_var33_ult1",
                          "num_trasp_var17_out_ult1","delta_imp_amort_var34_1y3","delta_imp_trasp_var33_out_1y3",
                          "delta_num_trasp_var33_out_1y3","ind_var13_medio","ind_var13_medio_0","ind_var18","ind_var18_0",
                          "ind_var29","ind_var34","ind_var34_0","ind_var6","ind_var7_emit_ult1","num_meses_var13_medio_ult3",
                          "num_trasp_var17_in_ult1","num_trasp_var33_out_ult1","num_var13_medio","num_var13_medio_0",
                          "num_var29","num_var34","num_var34_0","num_var6","num_var7_emit_ult1")
                          
                          
colnameskeep_initial <- colnames(train[,!(colnames(train) %in% colums_drops_initial)])
train = train[,colnameskeep_initial]

colnameskeep_initial <- colnames(predict[,(colnames(predict) %in% colnames(train))])
colnameskeep_initial <- c("ID",colnameskeep_initial)
predict = predict[,colnameskeep_initial]

# Covert num to factor variables for train and preidct data

colnames(train)
colnames(predict)


for (i in 2:dim(train)[2]){
  if(length(unique(train[,i])) < 3){
  print(colnames(train)[i])
  train[,i] <- factor(train[,i])
  predict[,i] <- factor(predict[,i],levels=levels(train[,i]))
  }
}

## set the seed to make your partition reproductible
set.seed(123)

trainIndex <- createDataPartition(train$TARGET, p = .8,
                                  list = FALSE,
                                  times = 1)

SantanderTrain <- train[ trainIndex,]
SantanderTest  <- train[-trainIndex,]

#colnames(SantanderTrain)
#table(SantanderTrain$TARGET)
#train$delta_imp_reemb_var17_1y3 <- factor(train$delta_imp_reemb_var17_1y3)

table(SantanderTrain$TARGET)
table(SantanderTest$TARGET)
table(train$TARGET)

####################################### Training Model

RFmodel.rf <- randomForest(TARGET ~ .,data = SantanderTrain,
              importance=TRUE,
              mtry=25, # # of variables (default sqrt(p))
              #proximity=TRUE,
              ntree=200,
              #nodesize=5, #Min # of observations (default 1) - do CV
              #maxnodes=15, # Maximum number of terminal nodes trees (default max possible)
              type="classification", 
              #sampsize = c(250,250),
              keep.forest=TRUE)

round(head(RFmodel.rf$err.rate,202),4)  	# look at the error rate
min.err <- min(data.frame(RFmodel.rf$err.rate)["OOB"])	# find tree with minnimum error rate
min.err								# Minimum error rate
min.err.index <- which(data.frame(RFmodel.rf$err.rate)["OOB"]==min.err)
min.err.index							# Tree with minimum error

RFmodel.rf
summary(RFmodel.rf)
# summary(RFmodel.rf$test$err.rate)
head(RFmodel.rf$err.rate)
plot(RFmodel.rf$err.rate[,1]) # total error, it's learning until a point that it goes up again, due to 1's
plot(RFmodel.rf$err.rate[,2]) # error for 0, it's learning, it is going down
plot(RFmodel.rf$err.rate[,3]) # error for 1, it doesn't learn

# to see the importance of the variables, not only in the general error, as well the contribution to the flag (0,1)
rn <- round(importance(RFmodel.rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Plot variable importance
plot(RFmodel.rf, log="y")
varImpPlot(RFmodel.rf, n.var=20)
#MDSplot(RFmodel.rf, ytraining)
par(mfrow = c(2,2))

#RFmodel.rf$RFmodel.rf[n_tree]

summary(SantanderTrain)
colnames(SantanderTrain)

#------------------------------> Train ROC

colnames(SantanderTrain)

# Training ROC
# RF
probxRFtraining <- predict(RFmodel.rf, SantanderTrain[,-1], type="prob")
pred <- prediction(probxRFtraining[,"1"],matrix(SantanderTrain[,1])) 
# GBM
probxGBMtraining <- predict(fit.gbm, SantanderTrain[,-1], type="prob")
pred <- prediction(probxGBMtraining[,"1"],matrix(SantanderTrain[,1])) 

perf <- performance(pred, measure = "tpr", x.measure = "fpr") 
#plot(perf, print.cutoffs.at=seq(0,1,by=0.01))
plot(perf, col=rainbow(10), colorize=TRUE, lwd=3)
title("ROC Training")
abline(v=0.2)
abline(h=0.6)
auctraining <- performance(pred, measure = "auc")@y.values[[1]]
legend("bottomright",legend=c(paste("RF (AUC=",formatC(auctraining,digits=4,format="f"),")",sep="")),  
col=c("red"), lty=1)

# OOB ROC
pred <- prediction(RFmodel.rf$votes[,"1"],matrix(SantanderTrain[,1]))
perf <- performance(pred, measure = "tpr", x.measure = "fpr") 
aucOOB <- performance(pred, measure = "auc")@y.values[[1]]
#plot(perf, print.cutoffs.at=seq(0,1,by=0.01))
plot(perf, col=rainbow(10), colorize=TRUE, lwd=3)
title("ROC OOB")
abline(v=0.2)
abline(h=0.6)
legend("bottomright",legend=c(paste("RF (AUC=",formatC(aucOOB,digits=4,format="f"),")",sep="")),  
col=c("red"), lty=1)
#plot(perf, lwd=3)

#-----------------------------------> GBM

fitControl <- trainControl(
method = "repeatedcv", # The resampling method
number = 5, #10
repeats = 1)

TuneGrid <- expand.grid(n.trees = 300,interaction.depth = 15,shrinkage = 0.01,n.minobsinnode=10)
#TuneGrid <- expand.grid(n.trees = 1000,interaction.depth = 30,shrinkage = 0.001,n.minobsinnode=10)

fit.gbm <- train(TARGET ~ ., data = SantanderTrain,
method = "gbm",
trControl = fitControl,
verbose = FALSE,
weights = SantanderTrain$weights,
tuneGrid = TuneGrid
#,metric="ROC"
)

summary(fit.gbm)

####################################### Preparing Prediction Data


str(SantanderTrain, list.len=ncol(SantanderTrain))
str(predict, list.len=ncol(predict))

set.seed(200)


####################################### Prediction

str(SantanderTrain, list.len=ncol(SantanderTrain))
str(predict, list.len=ncol(predict))

str(sample_submission)
colnames(predict)
colnames(SantanderTest)

probxgotest <- predict(RFmodel.rf, predict, type="prob",na.action=na.roughfix)
probxgotest <- predict(fit.gbm, predict, type="prob",na.action=na.roughfix)

final <- data.frame(ID = predict[,"ID"], TARGET = probxgotest[,"1"])
getwd()

write.csv(final, "Santander_submission_v3.csv", row.names = F)

#----------------------------------> test ROC

#RF
probxRFtesttree <- predict(RFmodel.rf, SantanderTest[,-1], type="prob")
pred <- prediction(probxRFtesttree[,"1"],matrix(SantanderTest[,1]))

#GBM
probxGBMtesttree <- predict(fit.gbm, SantanderTest[,-1], type="prob")
pred <- prediction(probxGBMtesttree[,"1"],matrix(SantanderTest[,1]))

perf <- performance(pred, measure = "tpr", x.measure = "fpr") 
plot(perf, col=rainbow(10), colorize=TRUE, lwd=3)

title("ROC Test Tree")
abline(v=0.2)
abline(h=0.6)
auctest <- performance(pred, measure = "auc")@y.values[[1]]

legend("bottomright",legend=c(paste("RF (AUC=",formatC(auctest,digits=4,format="f"),")",sep="")),  
col=c("red"), lty=1)
